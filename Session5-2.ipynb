{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" src=\"libraries_short_color.png\" alt=\"NYU Libraries Logo\">\n",
    "\n",
    "# Data in/and the Humanities\n",
    "**[NYU Abu Dhabi Winter Institute in Digital Humanities](https://wp.nyu.edu/widh/)**\n",
    "## Course Session \\#5-2 -- Text as Data API Activity\n",
    "\n",
    "**Nicholas Wolf**<br/>\n",
    "[ORCID 0000-0001-5512-6151](https://orcid.org/0000-0001-5512-6151)\n",
    "\n",
    "This lesson is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "**Overview**\n",
    "\n",
    "In this sesssion we combine the affordances of machine-readable full-text accessible via an Application Programming Interface (API) endpoint. Specifically, we'll make use of a tremendous resource in the form of the Library of Congress's [Chronicling America](https://chroniclingamerica.loc.gov/about/). See also the [description of its API](https://chroniclingamerica.loc.gov/about/api/). \n",
    "\n",
    "In addition to revisiting our JSON data structures, we'll use some advanced techniques in Google Sheets to add to our ability to munge data.\n",
    "\n",
    "**Materials**\n",
    "\n",
    " - Web browser, Google Sheets\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reflection\n",
    "\n",
    "*Chronicling America* reports that the project contains millions of [digitized pages](https://chroniclingamerica.loc.gov/search/pages/results/#tab=tab_search) from 140,000 newspaper titles spanning 1789 to 1963. This project was built on a long-term NEH grant to select and digitize local newspapers for preservation.\n",
    "\n",
    "1. What general cautions should we take when drawing conclusions from these sources?\n",
    "\n",
    "Consider:\n",
    "\n",
    " - What limitations might we expect in the process of turning *digitized* newspapers turned into *machine-readable* texts?\n",
    " - How have newspapers changed over time?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using a Browser and API\n",
    "\n",
    "*Chronicling America* provides a helpful basic description of how to query its newspaper metadata and full text. Like many APIs, this one works by sending a properly formed URL via HTTP (the protocal that governs passing web content to local applications such as browsers). \n",
    "\n",
    "It notes that we need to send a URL request formed like this:\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan)\n",
    "\n",
    "...to query all newspaper titles with \"michigan\" present. Click on the query above to try it in your own browser. Note  this use of a \"?\" to denote the start of a set of parameters sent to the API endpoint (base URL). \n",
    "\n",
    "We can also ask for a different format, JSON:\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json)\n",
    "\n",
    "If you view the JSON results in Firefox, you'll get a nice human-readable version of your JSON. Otherwise, you may need to copy and paste the raw JSON into a text editor to understand its contents.\n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"screencaptures/json-page-example.png\" alt=\"Paginated Results\"><br clear=\"both\"><br/>\n",
    "\n",
    "\n",
    "Note that the results are given to you 20 at a time. This prevents your application/browser from crashing by receiving thousands or more of results at once. Instead, the system (like many APIs) relies on a paging system in which results are grouped into 20 and you must continually request results in batches to eventually download the full set of results. Pagination can be set like this:\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json)\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&page=2](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&page=2)\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&page=3](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&page=3)\n",
    "\n",
    "...etc.\n",
    "\n",
    "We do have another option, however, which is to explicitly tell the API how many results we want:\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&rows=200](https://chroniclingamerica.loc.gov/search/titles/results/?terms=michigan&format=json&rows=200)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploring Full Text and Parsing JSON\n",
    "\n",
    "Now that we know how this works, let's try to pull some interesting full-text data. The API documentation tells us that we can search for full-text results like this:\n",
    "\n",
    "[https://chroniclingamerica.loc.gov/search/pages/results/?andtext=thomas&format=json&rows=200](https://chroniclingamerica.loc.gov/search/pages/results/?andtext=thomas&format=json&rows=200)\n",
    "\n",
    "Let's try an interesting term like \"suffrage\" (or something of interest to you) and generate some JSON. Take a glance at your results.\n",
    "\n",
    "JSON is for robots. Let’s try this again in a more readable form using Google Sheets. Visit the Sheet below and make a copy of it for you to use: https://docs.google.com/spreadsheets/d/1AiqNl54veUn1lrVl8WTqMSN6RBA5qVWPLZPOCmeXtyo/edit?usp=sharing\n",
    "\n",
    "After opening it, click on File >> Make a Copy. This is a special premade Sheet that has a built in custom function that can pull JSON from a website and parse it as a table (thanks to this [neat little tutorial](https://medium.com/@paulgambill/how-to-import-json-data-into-google-spreadsheets-in-less-than-5-minutes-a3fede1a014a); read the details if you want to know how it works). To use it, you will type this function into a cell:\n",
    "\n",
    "=ImportJSON(\"https://chroniclingamerica.loc.gov/search/pages/results/?andtext=thomas&format=json&rows=200\")\n",
    "\n",
    "You should see the cell read \"Loading\" before producing a tabular version of the 200 results.\n",
    "\n",
    "<img align=\"left\" width=\"500\" src=\"screencaptures/sheets-load.png\" alt=\"Paginated Results\"><br clear=\"both\"><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Quick Analysis in Google Sheets\n",
    "\n",
    "We could now shift to OpenRefine for some cleanup, but note that Google Sheets, because it nicely protects the encoding of your data and ability to cleanly export to CSV without disrupting data types (e.g. forcing a date-like number to be a date without asking), it is a solid tool for some data cleaning.\n",
    "\n",
    "For example, let's say that we want to perform a quick examination of the frequency of the term \"suffrage\" (or whatever term you've selected) over time. We see that we have a column called \"Items Date\" (column K) but that it consists of a four digit year plus month and day concatenated into a single number. \n",
    "\n",
    "1. To pull out our year, create a new column at the end of the sheet and name it \"derived_year\". Enter the following formula in the second row:\n",
    "\n",
    "<pre>=LEFT(K2, 4)</pre>\n",
    "\n",
    "2. This tells Sheets to populate this column with the first 4 characters of the value in column K. Once you see the first value popup, hold down shift while the cell with the formula is activated, scroll to the bottom of the sheet to row 201, click the last row in the same column (activating/highlighting all cells below your initial formula cell), and press Control + D (or Command + D).<br/><br/>\n",
    "\n",
    "3. Highlight this entire year column, and at the bottom, select plus to create a new sheet. Select Control + C (or Command + C) to copy, and then visit the new sheet. In cell A1, click on Edit >> Paste Special and select paste values only. We now have a column of year values (not formulas).<br/><br/>\n",
    "\n",
    "4. Next, click on the column header and find the “funnel” filter button at the top. This activates quick filtering. Filter the values in your column A-Z to put them in chronological order.<br/><br/>\n",
    "\n",
    "5. Highlight the entire year column, and select from the main menu Insert >> Chart. If need be, set the chart type to line. This will get us a quick frequency count of the mentions of the selected word term over time.<br/><br/>\n",
    "\n",
    "<img align=\"left\" width=\"800\" src=\"screencaptures/sheets-chart.png\" alt=\"Paginated Results\"><br clear=\"both\"><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reflection\n",
    "\n",
    " 1. How explanatory is a raw count of frequency of a term appearing in a corpus over time?<br/><br/>\n",
    " 2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
